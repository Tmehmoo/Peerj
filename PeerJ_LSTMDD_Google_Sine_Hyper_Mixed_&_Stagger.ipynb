{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tmehmoo/Peerj/blob/main/PeerJ_LSTMDD_Google_Sine_Hyper_Mixed_%26_Stagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4kidZ3cM2Nv"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erdvdFBzPzoT"
      },
      "source": [
        "#libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdD9SIa3KUON",
        "outputId": "00e009dd-aa2c-4218-8fa8-818d0c720965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dynarray in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dynarray) (1.23.5)\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.23.5)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install dynarray\n",
        "!pip install deap\n",
        "!pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGiZM8dOVCel"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "from dynarray import DynamicArray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import csv\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "import seaborn as sb\n",
        "from keras.layers import Layer, TimeDistributed, RepeatVector\n",
        "from keras.layers import Bidirectional, Flatten, Concatenate\n",
        "from keras.layers import Lambda, Permute, dot\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.layers import Attention\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model# Download the dataset\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "from dynarray import DynamicArray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import csv\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "# importing the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model# Download the dataset\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "from dynarray import DynamicArray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import csv\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as mp\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "sns.set()\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "import keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.layers import Layer, TimeDistributed, RepeatVector\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Flatten, Input, Concatenate\n",
        "from keras.layers import Lambda, Permute, dot\n",
        "from keras import backend as K\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import numpy as np\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deap import base, creator, tools, algorithms\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.layers import Attention\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deap import base, creator, tools, algorithms\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import kstest\n",
        "from dynarray import DynamicArray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_curve\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "from keras.layers import Layer, TimeDistributed, RepeatVector\n",
        "from keras.layers import Bidirectional, Flatten, Concatenate\n",
        "from keras.layers import Lambda, Permute, dot\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.layers import Attention\n",
        "from deap import base, creator, tools, algorithms\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfVnbzU6jtMV"
      },
      "source": [
        "\n",
        "#LSTMDD for Google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmKK-nzmJqPy"
      },
      "source": [
        "##Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly-oSjYZIwMS",
        "outputId": "a8795178-5e0a-4aaf-d814-074ba24c0746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-f9b1efc42c3c>:24: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
            "  merged =merged[~merged.isin([np.nan, np.inf, -np.inf]).any(1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "811\n"
          ]
        }
      ],
      "source": [
        "epochs=50\n",
        "batchsize=32\n",
        "nooffile=2\n",
        "#n is no of features\n",
        "n=5\n",
        "# n=5\n",
        " # Download the dataset\n",
        "merged = pd.read_csv('/content/drive/My Drive/part-00001-of-00500.csv', header=None)\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/mixed_0101_gradual.csv', header='infer')\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/sea4.csv', header='infer')\n",
        "# merged = pd.read_csv('/content/drive/My Drive/sine3.csv',  header=None)\n",
        "# merged = pd.read_csv('/content/drive/My Drive/hyperplane1.csv', header=None)\n",
        "# merged = pd.read_csv('/content/drive/My Drive/mixed5.csv', header=None)\n",
        "# merged = pd.read_csv('/content/drive/My Drive/stagger4.csv', header=None)\n",
        "i=1\n",
        "# while i<nooffile:\n",
        "#   a=pd.read_csv(\"/content/drive/My Drive/part-0000\"+str(i)+\"-of-00500.csv\")\n",
        "#   merged=np.concatenate([merged, a])\n",
        "#   a=0\n",
        "#   i=i+1\n",
        "# del a\n",
        "merged=pd.DataFrame(data=merged)\n",
        "merged.fillna(merged.mean())\n",
        "merged =merged[~merged.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "\n",
        "merged=np.array(merged)\n",
        "labels =merged[:,n] #5\n",
        "\n",
        "merged=np.delete(merged,[n], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0OHI4DgJ5oC"
      },
      "source": [
        "##Balance Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzedy-znzgLb"
      },
      "outputs": [],
      "source": [
        "labels = np.array(y11)  # Ensure labels are integers\n",
        "data = merged\n",
        "\n",
        "#Identify unique classes\n",
        "unique_classes = np.unique(labels)\n",
        "\n",
        "#Determine the minority class size\n",
        "minority_class_size = min(np.bincount(labels))\n",
        "\n",
        "# Initialize arrays to store balanced data and labels\n",
        "balanced_data = []\n",
        "balanced_labels = []\n",
        "\n",
        "# Undersample\n",
        "for class_label in unique_classes:\n",
        "    class_data = data[labels == class_label]\n",
        "    undersampled_class_data = resample(class_data,\n",
        "                                       replace=False,\n",
        "                                       n_samples=minority_class_size,\n",
        "                                       random_state=42)\n",
        "\n",
        "    # Append undersampled data and labels to balanced arrays\n",
        "    balanced_data.extend(undersampled_class_data)\n",
        "    balanced_labels.extend([class_label] * minority_class_size)\n",
        "\n",
        "    print(f\"Class {class_label}: Number of Records after Undersampling = {minority_class_size}\")\n",
        "\n",
        "# Convert balanced_data and balanced_labels to numpy arrays\n",
        "balanced_data = np.array(balanced_data)\n",
        "balanced_labels = np.array(balanced_labels)\n",
        "\n",
        "# Combine the undersampled data and labels\n",
        "balanced_data_with_labels = np.column_stack((balanced_data, balanced_labels))\n",
        "\n",
        "# Shuffle data\n",
        "np.random.shuffle(balanced_data_with_labels)\n",
        "\n",
        "# Separate labels and features for the balanced data\n",
        "balanced_labels = balanced_data_with_labels[:, -1].astype(int)  # Convert labels to integers\n",
        "balanced_features = balanced_data_with_labels[:, :-1]\n",
        "\n",
        "# Verify that the label class is changed correctly\n",
        "print(\"Balanced Labels:\", balanced_labels)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(balanced_features, balanced_labels, test_size=0.40, shuffle=False)\n",
        "\n",
        "\n",
        "X_train = np.array(train_data)\n",
        "X_test = np.array(test_data)\n",
        "train_labels= np.array(train_labels)\n",
        "test_labels= np.array(test_labels)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "test_labels=np.reshape(test_labels,(test_labels.shape[0], 1))\n",
        "train_labels=np.reshape(train_labels,(train_labels.shape[0], 1))\n",
        "\"\"#Non- Gaussian Code  #LSTM AT HT\"\"\"\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(train_labels)\n",
        "X_test  = np.array(X_test)\n",
        "y_test  = np.array(test_labels)\n",
        "input_shape = ( 1,7)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(X_train, train_labels, test_size=0.3, shuffle=False)\n",
        "TrainX=X_train1\n",
        "ValidationX= X_val\n",
        "TestingX=X_test\n",
        "TrainY=y_train1\n",
        "ValidationY= y_val\n",
        "TestingY=y_test\n",
        "trainX_count = len(TrainX)\n",
        "ValidationX_count = len(ValidationX)\n",
        "testingX_count = len(TestingX)\n",
        "trainY_count = len(TrainY)\n",
        "ValidationY_count = len(ValidationY)\n",
        "testingY_count = len(TestingY)\n",
        "\n",
        "trainX_shape = TrainX.shape\n",
        "ValidationX_shape = ValidationX.shape\n",
        "testingX_shape = TestingX.shape\n",
        "trainY_shape = TrainY.shape\n",
        "ValidationY_shape = ValidationY.shape\n",
        "testingY_shape = TestingY.shape\n",
        "\n",
        "print(f\"TrainX Count: {trainX_count}, TrainX Shape: {trainX_shape}\")#, TrainX: {TrainX}\")\n",
        "print(f\"ValidationX Count: {ValidationX_count}, ValidationX Shape: {ValidationX_shape}\")#, validationX: {ValidationX}\")\n",
        "print(f\"TestingX Count: {testingX_count}, TestingX Shape: {testingX_shape}\")#, TestingX: {TestingX}\")\n",
        "print(f\"TrainY Count: {trainY_count}, TrainY Shape: {trainY_shape}\")#, TrainY: {TrainY}\")\n",
        "print(f\"ValidationY Count: {ValidationY_count}, ValidationY Shape: {ValidationY_shape}\")#, validationY: {ValidationY}\")\n",
        "print(f\"TestingY Count: {testingY_count}, TestingY Shape: {testingY_shape}\")#, TestingY: {TestingY}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "6m7r1lsowOBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6J3MKIaCDL_",
        "outputId": "63fa4258-5165-4227-ba43-28a3db609d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9522342064714946\n",
            "Precision: 0.946031746031746\n",
            "Recall: 0.9551282051282052\n",
            "F-score: 0.9505582137161085\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[320  17]\n",
            " [ 14 298]]\n",
            "False Positive Rate (FPR): 0.050445103857566766\n",
            "False Negative Rate (FNR): 0.04487179487179487\n",
            "TN 320   FP 17   FN 14   TP 298\n",
            "gen\tnevals\tavg     \tmin     \tmax     \n",
            "0  \t4     \t0.973035\t0.952234\t0.993837\n",
            "Units: 160 Batch Size: 96 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 3s 87ms/step - loss: 0.6904 - val_loss: 0.6870\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.6815 - val_loss: 0.6807\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.6724 - val_loss: 0.6720\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.6614 - val_loss: 0.6615\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.6479 - val_loss: 0.6474\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.6304 - val_loss: 0.6291\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.6084 - val_loss: 0.6047\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.5789 - val_loss: 0.5709\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.5406 - val_loss: 0.5307\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.4948 - val_loss: 0.4853\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.4459 - val_loss: 0.4322\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.3951 - val_loss: 0.3838\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3459 - val_loss: 0.3345\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.3004 - val_loss: 0.2873\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.2604 - val_loss: 0.2474\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.2263 - val_loss: 0.2176\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1994 - val_loss: 0.1901\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1781 - val_loss: 0.1672\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1610 - val_loss: 0.1488\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1465 - val_loss: 0.1369\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1352 - val_loss: 0.1261\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1245 - val_loss: 0.1124\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1171 - val_loss: 0.1040\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1094 - val_loss: 0.0990\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.1042 - val_loss: 0.0909\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.1002 - val_loss: 0.0838\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0965 - val_loss: 0.0786\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.0915 - val_loss: 0.0782\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0880 - val_loss: 0.0725\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0849 - val_loss: 0.0673\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0823 - val_loss: 0.0645\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0797 - val_loss: 0.0626\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0774 - val_loss: 0.0608\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0759 - val_loss: 0.0591\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.0740 - val_loss: 0.0562\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0725 - val_loss: 0.0542\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.0709 - val_loss: 0.0526\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0694 - val_loss: 0.0510\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 0.0684 - val_loss: 0.0496\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0681 - val_loss: 0.0503\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0682 - val_loss: 0.0478\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0666 - val_loss: 0.0475\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0654 - val_loss: 0.0459\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0636 - val_loss: 0.0452\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0626 - val_loss: 0.0444\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0619 - val_loss: 0.0435\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0611 - val_loss: 0.0430\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0607 - val_loss: 0.0414\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0597 - val_loss: 0.0405\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0590 - val_loss: 0.0398\n",
            "21/21 [==============================] - 1s 2ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9922958397534669\n",
            "Precision: 0.9842271293375394\n",
            "Recall: 1.0\n",
            "F-score: 0.9920508744038156\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[332   5]\n",
            " [  0 312]]\n",
            "False Positive Rate (FPR): 0.01483679525222552\n",
            "False Negative Rate (FNR): 0.0\n",
            "TN 332   FP 5   FN 0   TP 312\n",
            "Units: 96 Batch Size: 532 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 603ms/step - loss: 0.6943 - val_loss: 0.6922\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6916 - val_loss: 0.6907\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6896 - val_loss: 0.6893\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6877 - val_loss: 0.6878\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6859 - val_loss: 0.6866\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6844 - val_loss: 0.6854\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6828 - val_loss: 0.6842\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6812 - val_loss: 0.6830\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6795 - val_loss: 0.6817\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6777 - val_loss: 0.6803\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6759 - val_loss: 0.6790\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6740 - val_loss: 0.6776\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.6721 - val_loss: 0.6762\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6701 - val_loss: 0.6745\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6678 - val_loss: 0.6722\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6652 - val_loss: 0.6697\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6624 - val_loss: 0.6673\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6598 - val_loss: 0.6648\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6569 - val_loss: 0.6621\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6539 - val_loss: 0.6592\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.6507 - val_loss: 0.6561\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6473 - val_loss: 0.6530\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6438 - val_loss: 0.6496\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6401 - val_loss: 0.6459\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6361 - val_loss: 0.6420\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6320 - val_loss: 0.6379\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6276 - val_loss: 0.6336\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6231 - val_loss: 0.6290\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6183 - val_loss: 0.6241\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6132 - val_loss: 0.6189\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6080 - val_loss: 0.6134\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6024 - val_loss: 0.6077\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5967 - val_loss: 0.6017\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5906 - val_loss: 0.5955\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5844 - val_loss: 0.5889\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5779 - val_loss: 0.5820\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5711 - val_loss: 0.5749\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5641 - val_loss: 0.5674\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5569 - val_loss: 0.5600\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5493 - val_loss: 0.5522\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5417 - val_loss: 0.5443\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5337 - val_loss: 0.5362\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5255 - val_loss: 0.5279\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5172 - val_loss: 0.5196\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5087 - val_loss: 0.5113\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4999 - val_loss: 0.5029\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4908 - val_loss: 0.4945\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4818 - val_loss: 0.4855\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4724 - val_loss: 0.4762\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4629 - val_loss: 0.4668\n",
            "21/21 [==============================] - 1s 3ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9568567026194145\n",
            "Precision: 0.9226190476190477\n",
            "Recall: 0.9935897435897436\n",
            "F-score: 0.9567901234567902\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[311  26]\n",
            " [  2 310]]\n",
            "False Positive Rate (FPR): 0.0771513353115727\n",
            "False Negative Rate (FNR): 0.00641025641025641\n",
            "TN 311   FP 26   FN 2   TP 310\n",
            "1  \t2     \t0.983051\t0.956857\t0.993837\n",
            "Units: 160 Batch Size: 48 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "17/17 [==============================] - 5s 69ms/step - loss: 0.6842 - val_loss: 0.6794\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.6649 - val_loss: 0.6595\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.6340 - val_loss: 0.6223\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.5838 - val_loss: 0.5625\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.5127 - val_loss: 0.4827\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.4276 - val_loss: 0.3953\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.3413 - val_loss: 0.3112\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.2671 - val_loss: 0.2415\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.2125 - val_loss: 0.1927\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1733 - val_loss: 0.1605\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1478 - val_loss: 0.1342\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1294 - val_loss: 0.1164\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1156 - val_loss: 0.1012\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1062 - val_loss: 0.0915\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0978 - val_loss: 0.0812\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0916 - val_loss: 0.0759\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0859 - val_loss: 0.0688\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0818 - val_loss: 0.0646\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0783 - val_loss: 0.0611\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0758 - val_loss: 0.0580\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0749 - val_loss: 0.0560\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0717 - val_loss: 0.0525\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0685 - val_loss: 0.0506\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0672 - val_loss: 0.0486\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0654 - val_loss: 0.0472\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0638 - val_loss: 0.0451\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0623 - val_loss: 0.0437\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0610 - val_loss: 0.0427\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0605 - val_loss: 0.0412\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0589 - val_loss: 0.0398\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0578 - val_loss: 0.0384\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0573 - val_loss: 0.0376\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0571 - val_loss: 0.0378\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0556 - val_loss: 0.0357\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0547 - val_loss: 0.0351\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0538 - val_loss: 0.0339\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0537 - val_loss: 0.0332\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0523 - val_loss: 0.0326\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0517 - val_loss: 0.0314\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0541 - val_loss: 0.0310\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0501 - val_loss: 0.0298\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0496 - val_loss: 0.0290\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0490 - val_loss: 0.0283\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0490 - val_loss: 0.0277\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0473 - val_loss: 0.0285\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0487 - val_loss: 0.0268\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0469 - val_loss: 0.0257\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0458 - val_loss: 0.0253\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0463 - val_loss: 0.0243\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0460 - val_loss: 0.0237\n",
            "21/21 [==============================] - 1s 4ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9938366718027735\n",
            "Precision: 0.9873417721518988\n",
            "Recall: 1.0\n",
            "F-score: 0.9936305732484078\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[333   4]\n",
            " [  0 312]]\n",
            "False Positive Rate (FPR): 0.011869436201780416\n",
            "False Negative Rate (FNR): 0.0\n",
            "TN 333   FP 4   FN 0   TP 312\n",
            "Units: 32 Batch Size: 48 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "17/17 [==============================] - 4s 65ms/step - loss: 0.6904 - val_loss: 0.6891\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.6839 - val_loss: 0.6854\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6768 - val_loss: 0.6792\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6665 - val_loss: 0.6691\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.6506 - val_loss: 0.6523\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.6276 - val_loss: 0.6287\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5960 - val_loss: 0.5958\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.5562 - val_loss: 0.5597\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.5109 - val_loss: 0.5173\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.4647 - val_loss: 0.4746\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.4179 - val_loss: 0.4261\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3735 - val_loss: 0.3758\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.3286 - val_loss: 0.3305\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.2876 - val_loss: 0.2864\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2512 - val_loss: 0.2465\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.2193 - val_loss: 0.2145\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1937 - val_loss: 0.1873\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.1720 - val_loss: 0.1629\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.1546 - val_loss: 0.1442\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1406 - val_loss: 0.1284\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.1277 - val_loss: 0.1139\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1179 - val_loss: 0.1031\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1096 - val_loss: 0.0949\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.1033 - val_loss: 0.0876\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0981 - val_loss: 0.0806\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0932 - val_loss: 0.0760\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0893 - val_loss: 0.0710\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0857 - val_loss: 0.0668\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0831 - val_loss: 0.0643\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0802 - val_loss: 0.0606\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0782 - val_loss: 0.0581\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0763 - val_loss: 0.0560\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0540\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0727 - val_loss: 0.0520\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0718 - val_loss: 0.0505\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0696 - val_loss: 0.0491\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0690 - val_loss: 0.0475\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0675 - val_loss: 0.0463\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0661 - val_loss: 0.0452\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0656 - val_loss: 0.0439\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0647 - val_loss: 0.0432\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0631 - val_loss: 0.0419\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0410\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0614 - val_loss: 0.0402\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0605 - val_loss: 0.0394\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.0598 - val_loss: 0.0385\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0593 - val_loss: 0.0378\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0583 - val_loss: 0.0373\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.0578 - val_loss: 0.0364\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.0574 - val_loss: 0.0356\n",
            "21/21 [==============================] - 1s 2ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9907550077041603\n",
            "Precision: 0.9841772151898734\n",
            "Recall: 0.9967948717948718\n",
            "F-score: 0.9904458598726115\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[332   5]\n",
            " [  1 311]]\n",
            "False Positive Rate (FPR): 0.01483679525222552\n",
            "False Negative Rate (FNR): 0.003205128205128205\n",
            "TN 332   FP 5   FN 1   TP 311\n",
            "Units: 160 Batch Size: 48 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "17/17 [==============================] - 4s 48ms/step - loss: 0.6886 - val_loss: 0.6844\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.6760 - val_loss: 0.6685\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.6544 - val_loss: 0.6396\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.6170 - val_loss: 0.5891\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5579 - val_loss: 0.5175\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.4795 - val_loss: 0.4270\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.3868 - val_loss: 0.3348\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2982 - val_loss: 0.2552\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2303 - val_loss: 0.1987\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1829 - val_loss: 0.1605\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1518 - val_loss: 0.1312\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1308 - val_loss: 0.1148\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1146 - val_loss: 0.0986\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1036 - val_loss: 0.0878\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0955 - val_loss: 0.0778\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0890 - val_loss: 0.0724\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.0833 - val_loss: 0.0650\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0787 - val_loss: 0.0609\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0749 - val_loss: 0.0578\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0731 - val_loss: 0.0545\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0703 - val_loss: 0.0510\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0694 - val_loss: 0.0496\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0660 - val_loss: 0.0479\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0646 - val_loss: 0.0457\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0629 - val_loss: 0.0445\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0623 - val_loss: 0.0426\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0615 - val_loss: 0.0409\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0588 - val_loss: 0.0397\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0581 - val_loss: 0.0385\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0568 - val_loss: 0.0372\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0564 - val_loss: 0.0364\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0559 - val_loss: 0.0350\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0541 - val_loss: 0.0342\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0531 - val_loss: 0.0334\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0529 - val_loss: 0.0324\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0522 - val_loss: 0.0313\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0512 - val_loss: 0.0308\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0507 - val_loss: 0.0298\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0500 - val_loss: 0.0289\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0503 - val_loss: 0.0290\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0487 - val_loss: 0.0275\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0481 - val_loss: 0.0268\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0475 - val_loss: 0.0260\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0466 - val_loss: 0.0253\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0462 - val_loss: 0.0247\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0457 - val_loss: 0.0244\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0455 - val_loss: 0.0242\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.0458 - val_loss: 0.0238\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0432 - val_loss: 0.0226\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0442 - val_loss: 0.0217\n",
            "21/21 [==============================] - 1s 5ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9938366718027735\n",
            "Precision: 0.9873417721518988\n",
            "Recall: 1.0\n",
            "F-score: 0.9936305732484078\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[333   4]\n",
            " [  0 312]]\n",
            "False Positive Rate (FPR): 0.011869436201780416\n",
            "False Negative Rate (FNR): 0.0\n",
            "TN 333   FP 4   FN 0   TP 312\n",
            "Units: 1 Batch Size: 96 Dropout Rate: 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 4s 81ms/step - loss: 0.6839 - val_loss: 0.6847\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6798 - val_loss: 0.6806\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6765 - val_loss: 0.6785\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6740 - val_loss: 0.6769\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6716 - val_loss: 0.6759\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6692 - val_loss: 0.6744\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6665 - val_loss: 0.6714\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6637 - val_loss: 0.6689\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6607 - val_loss: 0.6667\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6573 - val_loss: 0.6633\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6535 - val_loss: 0.6606\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6495 - val_loss: 0.6565\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6452 - val_loss: 0.6523\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6404 - val_loss: 0.6464\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6352 - val_loss: 0.6410\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6295 - val_loss: 0.6365\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6234 - val_loss: 0.6306\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6169 - val_loss: 0.6251\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6099 - val_loss: 0.6175\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6024 - val_loss: 0.6074\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5945 - val_loss: 0.5988\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5862 - val_loss: 0.5908\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5770 - val_loss: 0.5813\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5674 - val_loss: 0.5711\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5573 - val_loss: 0.5619\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5466 - val_loss: 0.5521\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5354 - val_loss: 0.5402\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5239 - val_loss: 0.5282\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.5120 - val_loss: 0.5163\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4996 - val_loss: 0.5040\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4875 - val_loss: 0.4919\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4753 - val_loss: 0.4838\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4630 - val_loss: 0.4717\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4501 - val_loss: 0.4578\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4375 - val_loss: 0.4464\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4251 - val_loss: 0.4339\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4132 - val_loss: 0.4204\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4008 - val_loss: 0.4102\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3890 - val_loss: 0.3989\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3773 - val_loss: 0.3867\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3661 - val_loss: 0.3756\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3549 - val_loss: 0.3638\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3446 - val_loss: 0.3537\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3342 - val_loss: 0.3427\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3244 - val_loss: 0.3322\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3150 - val_loss: 0.3235\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3062 - val_loss: 0.3146\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2976 - val_loss: 0.3043\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2894 - val_loss: 0.2968\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.2813 - val_loss: 0.2877\n",
            "21/21 [==============================] - 2s 11ms/step\n",
            "y_test: [[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "y_pred_binary: [1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
            " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0.]\n",
            "Accuracy: 0.9537750385208013\n",
            "Precision: 0.9246987951807228\n",
            "Recall: 0.9839743589743589\n",
            "F-score: 0.953416149068323\n",
            "y_test shape: (649, 1)\n",
            "y_pred_binary shape: (649,)\n",
            "y_pred_class shape: (649, 1, 1)\n",
            "y_test data type: int64\n",
            "y_pred_binary data type: float32\n",
            "Confusion matrix: [[312  25]\n",
            " [  5 307]]\n",
            "False Positive Rate (FPR): 0.07418397626112759\n",
            "False Negative Rate (FNR): 0.016025641025641024\n",
            "TN 312   FP 25   FN 5   TP 307\n",
            "2  \t4     \t0.983051\t0.953775\t0.993837\n",
            "3  \t0     \t0.993837\t0.993837\t0.993837\n",
            "Units: 160 Batch Size: 48 Dropout Rate: 0.1\n",
            "Epoch 1/50\n",
            "17/17 [==============================] - 8s 118ms/step - loss: 0.6846 - val_loss: 0.6815\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.6663 - val_loss: 0.6640\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.6387 - val_loss: 0.6335\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.5956 - val_loss: 0.5865\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 0.5363 - val_loss: 0.5252\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.4633 - val_loss: 0.4482\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.3804 - val_loss: 0.3592\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.3004 - val_loss: 0.2758\n",
            "Epoch 9/50\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.2534"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-571e051b1489>\u001b[0m in \u001b[0;36m<cell line: 182>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;31m# Run the evolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m population, logbook = algorithms.eaSimple(\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moffspring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-571e051b1489>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Make predictions on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Convert the data to numpy arrays\n",
        "X_train = np.array(train_data)\n",
        "X_test = np.array(test_data)\n",
        "train_labels= np.array(train_labels)\n",
        "test_labels= np.array(test_labels)\n",
        "\n",
        "# Reshape the data to 3D arrays\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "test_labels=np.reshape(test_labels,(test_labels.shape[0], 1))\n",
        "train_labels=np.reshape(train_labels,(train_labels.shape[0], 1))\n",
        "\n",
        "\"\"\"#Non- Gaussian Code  #LSTM AT HT\"\"\"\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(train_labels)\n",
        "X_test  = np.array(X_test)\n",
        "y_test  = np.array(test_labels)\n",
        "# y_test = y_test.flatten()\n",
        "\"\"\"#LSTM AT HY GA\"\"\"\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the fitness function\n",
        "def evaluate_model(individual):\n",
        "    # Extract the hyperparameters from the individual\n",
        "    units = individual[0]\n",
        "    batch_size = individual[1]\n",
        "    dropout_rate = individual[2]\n",
        "    if units == 0:\n",
        "        units = 32\n",
        "    if batch_size == 0:\n",
        "        batch_size = 32\n",
        "    if dropout_rate == 0:\n",
        "        dropout_rate = 0.1\n",
        "\n",
        "    print(\"Units:\", units, \"Batch Size:\", batch_size, \"Dropout Rate:\", dropout_rate)\n",
        "\n",
        "    # Build the LSTM model with the specified hyperparameters\n",
        "    inputs = Input(shape=(1, 10))\n",
        "    lstm_out, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(inputs)\n",
        "    attention_out = Attention()([lstm_out, lstm_out])\n",
        "    dense_out = Dense(16, activation='relu')(attention_out)\n",
        "    outputs = Dense(1, activation='sigmoid')(dense_out)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train1, y_train1, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "    # Make predictions on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.where(y_pred > 0.5, 1, 0)\n",
        "    y_pred_binary = np.round(y_pred).flatten()\n",
        "    if len(y_test) != len(y_pred_classes):\n",
        "     raise ValueError(\"Mismatch in target shapes.\")\n",
        "    y_pred_binary=np.array(y_pred_binary)\n",
        "    print(\"y_test:\", y_test)\n",
        "    print(\"y_pred_binary:\", y_pred_binary)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "    precision = precision_score(y_test, y_pred_binary)\n",
        "    recall = recall_score(y_test, y_pred_binary)\n",
        "    f1 = f1_score(y_test, y_pred_binary)\n",
        "    # Ensure the targets have the same shape\n",
        "\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F-score:\", f1)\n",
        "    # macro_f1 = f1_score(y_test, y_pred_classes, average='macro')\n",
        "    # print(\"Macro F-score:\",macro_f1)\n",
        "    # macro_f1 = f1_score(y_test, y_pred_classes, average='micro')\n",
        "    # print(\"Micro F-score:\",macro_f1)\n",
        "\n",
        "    if len(y_test) != len(y_pred_binary) or len(y_test) != len(y_pred_classes):\n",
        "     raise ValueError(\"Mismatch in target shapes.\")\n",
        "    # Check the shapes and data types of y_test and y_pred_binary\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "    print(\"y_pred_binary shape:\", y_pred_binary.shape)\n",
        "    print(\"y_pred_class shape:\", y_pred_classes.shape)\n",
        "    print(\"y_test data type:\", y_test.dtype)\n",
        "    print(\"y_pred_binary data type:\", y_pred_binary.dtype)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
        "    print(\"Confusion matrix:\", conf_matrix)\n",
        "\n",
        "    # Unpack the values from the confusion matrix\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    fpr = fp / (fp + tn)\n",
        "    fnr = fn / (fn + tp)\n",
        "\n",
        "    print(\"False Positive Rate (FPR):\", fpr)\n",
        "    print(\"False Negative Rate (FNR):\", fnr)\n",
        "    print(\"TN\", tn, \"  FP\",fp,\"  FN\",fn,\"  TP\",tp)\n",
        "\n",
        "    # Return the fitness value (accuracy) as a tuple\n",
        "    return accuracy,\n",
        "\n",
        "# Define the individual and population size\n",
        "INDIVIDUAL_SIZE = 3\n",
        "POPULATION_SIZE = 4\n",
        "\n",
        "# Create the individual and population classes\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# Create the toolbox\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Define the hyperparameter ranges\n",
        "units_range = [32,64, 128]\n",
        "batch_size_range = [16, 32, 64,500,1000]\n",
        "dropout_rate_range = [0.1, 0.2, 0.3]\n",
        "# Register the hyperparameters in the toolbox\n",
        "# Define the custom initialization function for units\n",
        "# def init_units():\n",
        "#     return np.random.choice(units_range)\n",
        "#     return np.random.choice(units_range)\n",
        "def init_units():\n",
        "    return int(np.random.choice(units_range)) + 32\n",
        "\n",
        "# Register the units attribute with the custom initialization function\n",
        "toolbox.register(\"units\", init_units)\n",
        "\n",
        "# toolbox.register(\"units\", np.random.choice, units_range)\n",
        "def init_batch_size_range():\n",
        "    return int(np.random.choice(batch_size_range)) + 32\n",
        "\n",
        "toolbox.register(\"batch_size\", init_batch_size_range)\n",
        "def init_dropout_rate_range():\n",
        "    return int(np.random.choice(dropout_rate_range))\n",
        "toolbox.register(\"dropout_rate\", init_dropout_rate_range)\n",
        "\n",
        "# # Define the individual initialization function\n",
        "# toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "#                  (toolbox.units, toolbox.batch_size, toolbox.dropout_rate), n=1)\n",
        "# Define the individual initialization function\n",
        "def init_individual():\n",
        "    return creator.Individual([toolbox.units(), toolbox.batch_size(), toolbox.dropout_rate()])\n",
        "\n",
        "# Register the individual initialization function\n",
        "toolbox.register(\"individual\", init_individual)\n",
        "# Define the population initialization function\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register the evaluation function\n",
        "toolbox.register(\"evaluate\", evaluate_model)\n",
        "\n",
        "# Register the selection, crossover, and mutation operations\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=2, indpb=0.5)\n",
        "\n",
        "# Define the number of generations and probability of crossover/mutation\n",
        "N_GENERATIONS = 10\n",
        "CROSSOVER_PROB = 0.8\n",
        "MUTATION_PROB = 0.2\n",
        "\n",
        "# Create the population\n",
        "population = toolbox.population(n=POPULATION_SIZE)\n",
        "\n",
        "# Create the hall of fame to store the best individuals\n",
        "hof = tools.HallOfFame(maxsize=1)\n",
        "\n",
        "# Define the statistics to collect during evolution\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "# Run the evolution\n",
        "population, logbook = algorithms.eaSimple(\n",
        "    population,\n",
        "    toolbox,\n",
        "    cxpb=CROSSOVER_PROB,\n",
        "    mutpb=MUTATION_PROB,\n",
        "    ngen=N_GENERATIONS,\n",
        "    stats=stats,\n",
        "    halloffame=hof,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Get the best individual from the hall of fame\n",
        "best_individual = hof[0]\n",
        "\n",
        "# Print\n",
        "print(\"Best Individual:\", best_individual)\n",
        "print(\"Fitness Value:\", best_individual.fitness.values[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAaOxrTwm0H"
      },
      "source": [
        "\n",
        "#LSTMDD for Other Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxn-QTrU5gFS"
      },
      "source": [
        "##Other Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM0pKJlgxF8P"
      },
      "outputs": [],
      "source": [
        "epochs=50\n",
        "batchsize=32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdbhOmQ29L4P"
      },
      "source": [
        "##Read Artifcial Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpHEU8BA9Olj",
        "outputId": "96ba22e1-ea79-4494-a0f6-b84fdc64a2b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-31-2cfc706dd4b5>:18: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  merged.fillna(merged.mean())\n"
          ]
        }
      ],
      "source": [
        "\n",
        " \"\"\"#Google Usgae Data\"\"\"\n",
        "\n",
        " #merged = pd.read_csv('/content/drive/My Drive/sine3.csv',  header=None)\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/hyperplane1.csv', header=None)\n",
        "# merged = pd.read_csv('/content/drive/My Drive/mixed5.csv', header=None)\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/ma5.csv', header=0)\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/sine24.csv', header=0)\n",
        " merged = pd.read_csv('/content/drive/My Drive/hyperr24.csv', header=0)\n",
        "# merged = pd.read_csv('/content/drive/My Drive/mixed24.csv', header=None)\n",
        "\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/b.csv', header=0)\n",
        "\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/stagger4.csv', header=None)\n",
        "\n",
        "#  merged = pd.read_csv('/content/drive/My Drive/part-00001-of-00500.csv', header=None)\n",
        " #dataframe.head()\n",
        " merged=pd.DataFrame(data=merged)\n",
        " merged.fillna(merged.mean())\n",
        "#  merged =merged[~merged.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "#  merged = merged.sample(n=10000, random_state=0)\n",
        " merged=np.array(merged)\n",
        " labels =merged[:,n] #5\n",
        "\n",
        "# merged=np.delete(merged,[n], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REMlY6Cywm0K"
      },
      "source": [
        "##Balance Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GDilO_z0wm0K",
        "outputId": "ed7b8a28-7a7b-499d-d279-399b6fd3a11d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0: Number of Records after Undersampling = 499999\n",
            "Class 1: Number of Records after Undersampling = 499999\n",
            "Balanced Labels: [1 1 0 ... 0 0 0]\n",
            "TrainX Count: 419998, TrainX Shape: (419998, 1, 31)\n",
            "ValidationX Count: 180000, ValidationX Shape: (180000, 1, 31)\n",
            "TestingX Count: 400000, TestingX Shape: (400000, 1, 31)\n",
            "TrainY Count: 419998, TrainY Shape: (419998, 1)\n",
            "ValidationY Count: 180000, ValidationY Shape: (180000, 1)\n",
            "TestingY Count: 400000, TestingY Shape: (400000, 1)\n"
          ]
        }
      ],
      "source": [
        "labels = np.array(y11, dtype=int)  # Ensure labels are integers\n",
        "data = merged[:, :-2]\n",
        "#Identify unique classes\n",
        "unique_classes = np.unique(labels)\n",
        "\n",
        "#Determine the minority class size\n",
        "minority_class_size = min(np.bincount(labels))\n",
        "\n",
        "# Initialize arrays to store balanced data and labels\n",
        "balanced_data = []\n",
        "balanced_labels = []\n",
        "\n",
        "# Undersample\n",
        "for class_label in unique_classes:\n",
        "    class_data = data[labels == class_label]\n",
        "    undersampled_class_data = resample(class_data,\n",
        "                                       replace=False,\n",
        "                                       n_samples=minority_class_size,\n",
        "                                       random_state=42)\n",
        "\n",
        "    # Append undersampled data and labels to balanced arrays\n",
        "    balanced_data.extend(undersampled_class_data)\n",
        "    balanced_labels.extend([class_label] * minority_class_size)\n",
        "\n",
        "    print(f\"Class {class_label}: Number of Records after Undersampling = {minority_class_size}\")\n",
        "\n",
        "# Convert balanced_data and balanced_labels to numpy arrays\n",
        "balanced_data = np.array(balanced_data)\n",
        "balanced_labels = np.array(balanced_labels)\n",
        "\n",
        "# Combine the undersampled data and labels\n",
        "balanced_data_with_labels = np.column_stack((balanced_data, balanced_labels))\n",
        "\n",
        "# Shuffle data\n",
        "np.random.shuffle(balanced_data_with_labels)\n",
        "\n",
        "# Separate labels and features for the balanced data\n",
        "balanced_labels = balanced_data_with_labels[:, -1].astype(int)  # Convert labels to integers\n",
        "balanced_features = balanced_data_with_labels[:, :-1]\n",
        "\n",
        "# Verify that the label class is changed correctly\n",
        "print(\"Balanced Labels:\", balanced_labels)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(balanced_features, balanced_labels, test_size=0.40, shuffle=False)\n",
        "\n",
        "\n",
        "X_train = np.array(train_data)\n",
        "X_test = np.array(test_data)\n",
        "train_labels= np.array(train_labels)\n",
        "test_labels= np.array(test_labels)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "test_labels=np.reshape(test_labels,(test_labels.shape[0], 1))\n",
        "train_labels=np.reshape(train_labels,(train_labels.shape[0], 1))\n",
        "\"\"#Non- Gaussian Code  #LSTM AT HT\"\"\"\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(train_labels)\n",
        "X_test  = np.array(X_test)\n",
        "y_test  = np.array(test_labels)\n",
        "input_shape = ( 1,7)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(X_train, train_labels, test_size=0.3, shuffle=False)\n",
        "TrainX=X_train1\n",
        "ValidationX= X_val\n",
        "TestingX=X_test\n",
        "TrainY=y_train1\n",
        "ValidationY= y_val\n",
        "TestingY=y_test\n",
        "trainX_count = len(TrainX)\n",
        "ValidationX_count = len(ValidationX)\n",
        "testingX_count = len(TestingX)\n",
        "trainY_count = len(TrainY)\n",
        "ValidationY_count = len(ValidationY)\n",
        "testingY_count = len(TestingY)\n",
        "\n",
        "trainX_shape = TrainX.shape\n",
        "ValidationX_shape = ValidationX.shape\n",
        "testingX_shape = TestingX.shape\n",
        "trainY_shape = TrainY.shape\n",
        "ValidationY_shape = ValidationY.shape\n",
        "testingY_shape = TestingY.shape\n",
        "\n",
        "print(f\"TrainX Count: {trainX_count}, TrainX Shape: {trainX_shape}\")#, TrainX: {TrainX}\")\n",
        "print(f\"ValidationX Count: {ValidationX_count}, ValidationX Shape: {ValidationX_shape}\")#, validationX: {ValidationX}\")\n",
        "print(f\"TestingX Count: {testingX_count}, TestingX Shape: {testingX_shape}\")#, TestingX: {TestingX}\")\n",
        "print(f\"TrainY Count: {trainY_count}, TrainY Shape: {trainY_shape}\")#, TrainY: {TrainY}\")\n",
        "print(f\"ValidationY Count: {ValidationY_count}, ValidationY Shape: {ValidationY_shape}\")#, validationY: {ValidationY}\")\n",
        "print(f\"TestingY Count: {testingY_count}, TestingY Shape: {testingY_shape}\")#, TestingY: {TestingY}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svs0EkkLzugT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a Min-Max scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Flatten the 3D arrays before scaling\n",
        "TrainX_flattened = TrainX.reshape((TrainX.shape[0], -1))\n",
        "ValidationX_flattened = ValidationX.reshape((ValidationX.shape[0], -1))\n",
        "TestingX_flattened = TestingX.reshape((TestingX.shape[0], -1))\n",
        "\n",
        "# Fit the scaler on the training data and transform the training data\n",
        "TrainX_normalized = scaler.fit_transform(TrainX_flattened)\n",
        "\n",
        "# Transform the validation and testing data using the same scaler\n",
        "ValidationX_normalized = scaler.transform(ValidationX_flattened)\n",
        "TestingX_normalized = scaler.transform(TestingX_flattened)\n",
        "import numpy as np\n",
        "\n",
        "# Cast your data to float32\n",
        "TrainX = np.array(TrainX, dtype=np.float32)\n",
        "ValidationX = np.array(ValidationX, dtype=np.float32)\n",
        "TestingX = np.array(TestingX, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmSCV0eTwm0L"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_bBAoawNwm0L"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # Convert the data to numpy arrays\n",
        "# X_train = np.array(train_data)\n",
        "# X_test = np.array(test_data)\n",
        "# train_labels= np.array(train_labels)\n",
        "# test_labels= np.array(test_labels)\n",
        "\n",
        "# # Reshape the data to 3D arrays\n",
        "# X_train = np.reshape(X_train, (X_train.shape[0],1, X_train.shape[1]))\n",
        "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "# test_labels=np.reshape(test_labels,(test_labels.shape[0], 1))\n",
        "# train_labels=np.reshape(train_labels,(train_labels.shape[0], 1))\n",
        "\n",
        "# \"\"\"#Non- Gaussian Code  #LSTM AT HT\"\"\"\n",
        "\n",
        "# X_train = np.array(X_train)\n",
        "# y_train = np.array(train_labels)\n",
        "# X_test  = np.array(X_test)\n",
        "# y_test  = np.array(test_labels)\n",
        "# # y_test = y_test.flatten()\n",
        "# \"\"\"#LSTM AT HY GA\"\"\"\n",
        "\n",
        "# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
        "# X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the fitness function\n",
        "def evaluate_model(individual):\n",
        "    # Extract the hyperparameters from the individual\n",
        "    units = individual[0]\n",
        "    batch_size = individual[1]\n",
        "    dropout_rate = individual[2]\n",
        "    if units == 0:\n",
        "        units = 32\n",
        "    if batch_size == 0:\n",
        "        batch_size = 32\n",
        "    if dropout_rate == 0:\n",
        "        dropout_rate = 0.1\n",
        "\n",
        "    print(\"Units:\", units, \"Batch Size:\", batch_size, \"Dropout Rate:\", dropout_rate)\n",
        "\n",
        "    # Build the LSTM model with the specified hyperparameters\n",
        "    inputs = Input(shape=(1, 31))\n",
        "    lstm_out, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(inputs)\n",
        "    attention_out = Attention()([lstm_out, lstm_out])\n",
        "    dense_out = Dense(16, activation='relu')(attention_out)\n",
        "    outputs = Dense(1, activation='sigmoid')(dense_out)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(TrainX, TrainY, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(ValidationX, ValidationY), callbacks=[early_stopping])\n",
        "\n",
        "    # Make predictions on test data\n",
        "    y_pred = model.predict(TestingX)\n",
        "    y_pred_classes = np.where(y_pred > 0.5, 1, 0)\n",
        "    y_pred_binary = np.round(y_pred).flatten()\n",
        "    if len(TestingY) != len(y_pred_classes):\n",
        "     raise ValueError(\"Mismatch in target shapes.\")\n",
        "    y_pred_binary=np.array(y_pred_binary)\n",
        "    print(\"TestingY:\", TestingY)\n",
        "    print(\"y_pred_binary:\", y_pred_binary)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(TestingY, y_pred_binary)\n",
        "    precision = precision_score(TestingY, y_pred_binary)\n",
        "    recall = recall_score(TestingY, y_pred_binary)\n",
        "    f1 = f1_score(TestingY, y_pred_binary)\n",
        "    # Ensure the targets have the same shape\n",
        "\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F-score:\", f1)\n",
        "    # macro_f1 = f1_score(y_test, y_pred_classes, average='macro')\n",
        "    # print(\"Macro F-score:\",macro_f1)\n",
        "    # macro_f1 = f1_score(y_test, y_pred_classes, average='micro')\n",
        "    # print(\"Micro F-score:\",macro_f1)\n",
        "\n",
        "    if len(TestingY) != len(y_pred_binary) or len(TestingY) != len(y_pred_classes):\n",
        "     raise ValueError(\"Mismatch in target shapes.\")\n",
        "    # Check the shapes and data types of y_test and y_pred_binary\n",
        "    print(\"y_test shape:\", TestingY.shape)\n",
        "    print(\"y_pred_binary shape:\", y_pred_binary.shape)\n",
        "    print(\"y_pred_class shape:\", y_pred_classes.shape)\n",
        "    print(\"y_test data type:\", TestingY.dtype)\n",
        "    print(\"y_pred_binary data type:\", y_pred_binary.dtype)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    conf_matrix = confusion_matrix(TestingY, y_pred_binary)\n",
        "    print(\"Confusion matrix:\", conf_matrix)\n",
        "\n",
        "    # Unpack the values from the confusion matrix\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    fpr = fp / (fp + tn)\n",
        "    fnr = fn / (fn + tp)\n",
        "\n",
        "    print(\"False Positive Rate (FPR):\", fpr)\n",
        "    print(\"False Negative Rate (FNR):\", fnr)\n",
        "    print(\"TN\", tn, \"  FP\",fp,\"  FN\",fn,\"  TP\",tp)\n",
        "\n",
        "    # Return the fitness value (accuracy) as a tuple\n",
        "    return accuracy,\n",
        "\n",
        "# Define the individual and population size\n",
        "INDIVIDUAL_SIZE = 3\n",
        "POPULATION_SIZE = 4\n",
        "\n",
        "# Create the individual and population classes\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "# Create the toolbox\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# Define the hyperparameter ranges\n",
        "units_range = [32,64, 128]\n",
        "batch_size_range = [16, 32, 64,500,1000]\n",
        "dropout_rate_range = [0.1, 0.2, 0.3]\n",
        "# Register the hyperparameters in the toolbox\n",
        "# Define the custom initialization function for units\n",
        "# def init_units():\n",
        "#     return np.random.choice(units_range)\n",
        "#     return np.random.choice(units_range)\n",
        "def init_units():\n",
        "    return int(np.random.choice(units_range)) + 32\n",
        "\n",
        "# Register the units attribute with the custom initialization function\n",
        "toolbox.register(\"units\", init_units)\n",
        "\n",
        "# toolbox.register(\"units\", np.random.choice, units_range)\n",
        "def init_batch_size_range():\n",
        "    return int(np.random.choice(batch_size_range)) + 32\n",
        "\n",
        "toolbox.register(\"batch_size\", init_batch_size_range)\n",
        "def init_dropout_rate_range():\n",
        "    return int(np.random.choice(dropout_rate_range))\n",
        "toolbox.register(\"dropout_rate\", init_dropout_rate_range)\n",
        "\n",
        "# # Define the individual initialization function\n",
        "# toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "#                  (toolbox.units, toolbox.batch_size, toolbox.dropout_rate), n=1)\n",
        "# Define the individual initialization function\n",
        "def init_individual():\n",
        "    return creator.Individual([toolbox.units(), toolbox.batch_size(), toolbox.dropout_rate()])\n",
        "\n",
        "# Register the individual initialization function\n",
        "toolbox.register(\"individual\", init_individual)\n",
        "# Define the population initialization function\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register the evaluation function\n",
        "toolbox.register(\"evaluate\", evaluate_model)\n",
        "\n",
        "# Register the selection, crossover, and mutation operations\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=2, indpb=0.5)\n",
        "\n",
        "# Define the number of generations and probability of crossover/mutation\n",
        "N_GENERATIONS = 10\n",
        "CROSSOVER_PROB = 0.8\n",
        "MUTATION_PROB = 0.2\n",
        "\n",
        "# Create the population\n",
        "population = toolbox.population(n=POPULATION_SIZE)\n",
        "\n",
        "# Create the hall of fame to store the best individuals\n",
        "hof = tools.HallOfFame(maxsize=1)\n",
        "\n",
        "# Define the statistics to collect during evolution\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)\n",
        "\n",
        "# Run the evolution\n",
        "population, logbook = algorithms.eaSimple(\n",
        "    population,\n",
        "    toolbox,\n",
        "    cxpb=CROSSOVER_PROB,\n",
        "    mutpb=MUTATION_PROB,\n",
        "    ngen=N_GENERATIONS,\n",
        "    stats=stats,\n",
        "    halloffame=hof,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Get the best individual from the hall of fame\n",
        "best_individual = hof[0]\n",
        "\n",
        "# Print\n",
        "print(\"Best Individual:\", best_individual)\n",
        "print(\"Fitness Value:\", best_individual.fitness.values[0])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "erdvdFBzPzoT",
        "k4jfHKxcHAnd"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}